{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Code Example - Part A\n",
    "\n",
    "This code baseline is inspired by and modified from [this great tutorial](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html).\n",
    "\n",
    "This code can achieve an accuracy of approximately 86.50% on CIFAR-10. Please set up the environment and run your experiments starting from this baseline. You are expected to achieve an accuracy higher than this baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data and pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# import some necessary packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    " \n",
    "import torchvision.datasets as tv_datasets\n",
    "import torchvision.transforms as tv_transforms\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some experimental setup\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_epochs = 128\n",
    "batch_size = 64\n",
    "num_workers = 2\n",
    "print_every = 200\n",
    "\n",
    "optim_name = \"Adam\"\n",
    "optim_kwargs = dict(\n",
    "    lr=3e-4,\n",
    "    weight_decay=1e-6,\n",
    ")\n",
    "\n",
    "# preprocessing pipeline for input images\n",
    "transformation = dict()\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    transformation[data_type] = tv_transforms.Compose(([\n",
    "        tv_transforms.RandomRotation(degrees=15),\n",
    "        tv_transforms.RandomHorizontalFlip(),\n",
    "        tv_transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    ] if is_train else []) + \n",
    "    [\n",
    "        tv_transforms.ToTensor(),\n",
    "        tv_transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# prepare datasets\n",
    "\n",
    "dataset, loader = {}, {}\n",
    "for data_type in (\"train\", \"test\"):\n",
    "    is_train = data_type==\"train\"\n",
    "    dataset[data_type] = tv_datasets.CIFAR10(\n",
    "        \n",
    "        root=\"./data\", train=is_train, download=False, transform=transformation[data_type],\n",
    "    )\n",
    "    loader[data_type] = torch.utils.data.DataLoader(\n",
    "        dataset[data_type], batch_size=batch_size, shuffle=is_train, num_workers=num_workers,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels, out_channels, kernel_size, stride=1, padding=0, Is_BN=True, Is_reg=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.Is_reg = Is_reg\n",
    "        self.Is_BN = Is_BN\n",
    "        if Is_BN:\n",
    "            self.bn = nn.BatchNorm2d(out_channels)\n",
    "        if Is_reg:\n",
    "            self.maxpool = nn.MaxPool2d(2)\n",
    "            self.dp = nn.Dropout(0.3)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # print(f\"[DEBUG] Input shape: {x.shape if x is not None else 'NULL'}\")\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        if self.Is_BN:\n",
    "            x = self.bn(x)\n",
    "        if self.Is_reg:\n",
    "            x = self.maxpool(x)\n",
    "            x = self.dp(x)\n",
    "        # print(f\"[DEBUG] Post-conv shape: {x.shape}\")\n",
    "        return x\n",
    "\n",
    "class ConvBs(nn.Module):\n",
    "    def __init__(self, num_layers,layer_dict):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            ConvBlock(**layer_dict[i])\n",
    "            for i in range(num_layers)\n",
    "        ])\n",
    "\n",
    "\n",
    "    def forward(self, x, train=True):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initial net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.28M\n"
     ]
    }
   ],
   "source": [
    "# our network architecture\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模块化设计\n",
    "# 增加filter 和layers\n",
    "# google net : v1:NIN+global pooling\n",
    "# v2: BN + 5*5 -> 2 3*3\n",
    "# v3: factorization\n",
    "# residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.init import xavier_uniform_, normal_\n",
    "\n",
    "class AddPositionEmbs(nn.Module):\n",
    "    def __init__(self, seq_len, emb_dim):\n",
    "        super().__init__()\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(1, seq_len, emb_dim) * 0.02)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pos_embedding\n",
    "\n",
    "class MlpBlock(nn.Module):\n",
    "    def __init__(self, in_dim, mlp_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(in_dim, mlp_dim)\n",
    "        self.fc2 = nn.Linear(mlp_dim, in_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 初始化参数\n",
    "        xavier_uniform_(self.fc1.weight)\n",
    "        normal_(self.fc1.bias, std=1e-6)\n",
    "        xavier_uniform_(self.fc2.weight)\n",
    "        normal_(self.fc2.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class Encoder1DBlock(nn.Module):\n",
    "    def __init__(self, hidden_dim, mlp_dim, num_heads, dropout=0.1, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.attn = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=attn_dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.mlp = MlpBlock(hidden_dim, mlp_dim, dropout)\n",
    "        \n",
    "        # 注意力层初始化\n",
    "        xavier_uniform_(self.attn.in_proj_weight)\n",
    "        normal_(self.attn.in_proj_bias, std=1e-6)\n",
    "        xavier_uniform_(self.attn.out_proj.weight)\n",
    "        normal_(self.attn.out_proj.bias, std=1e-6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.attn(\n",
    "            query=self.norm1(x),\n",
    "            key=self.norm1(x),\n",
    "            value=self.norm1(x)\n",
    "        )\n",
    "        x = x + self.dropout(attn_output)\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_dim, mlp_dim, num_heads, dropout=0.1, attn_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            Encoder1DBlock(hidden_dim, mlp_dim, num_heads, dropout, attn_dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.pos_emb = AddPositionEmbs(seq_len=65, emb_dim=hidden_dim)  # 默认ViT-B/16\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.norm = nn.LayerNorm(hidden_dim)\n",
    "\n",
    "    def forward(self, x, train=True):\n",
    "        x = self.pos_emb(x)\n",
    "        x = self.dropout(x) if train else x\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.norm(x)\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_classes, \n",
    "                 img_size=224,\n",
    "                 patch_size=16,\n",
    "                 hidden_dim=768,\n",
    "                 num_layers=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_dim=3072,\n",
    "                 dropout=0.1,\n",
    "                 attn_dropout=0.1,\n",
    "                 representation_size=None):\n",
    "        \n",
    "        super().__init__()\n",
    "        num_patches = (img_size // patch_size) ** 2\n",
    "        self.patch_embed = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=hidden_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=patch_size\n",
    "        )\n",
    "        \n",
    "        # 分类token\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, hidden_dim))\n",
    "        \n",
    "        # Transformer编码器\n",
    "        self.encoder = Encoder(\n",
    "            num_layers=num_layers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            mlp_dim=mlp_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            attn_dropout=attn_dropout\n",
    "        )\n",
    "        \n",
    "        # 分类头\n",
    "        self.pre_logits = nn.Identity()\n",
    "        if representation_size:\n",
    "            self.pre_logits = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, representation_size),\n",
    "                nn.Tanh()\n",
    "            )\n",
    "            hidden_dim = representation_size\n",
    "            \n",
    "        self.head = nn.Linear(hidden_dim, num_classes)\n",
    "        \n",
    "        # 初始化\n",
    "        nn.init.trunc_normal_(self.cls_token, std=0.02)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        # 卷积层初始化\n",
    "        nn.init.xavier_uniform_(self.patch_embed.weight)\n",
    "        nn.init.normal_(self.patch_embed.bias, std=1e-6)\n",
    "        \n",
    "        # 分类头初始化\n",
    "        nn.init.zeros_(self.head.weight)\n",
    "        nn.init.constant_(self.head.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 分块嵌入 [B, C, H, W] -> [B, hidden_dim, grid, grid]\n",
    "        x = self.patch_embed(x)  \n",
    "        B, C, H, W = x.shape\n",
    "        \n",
    "        # 展平并转置 [B, C, H*W] -> [B, H*W, C]\n",
    "        x = x.flatten(2).transpose(1, 2)  \n",
    "        \n",
    "        # 添加分类token\n",
    "        cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        \n",
    "        # Transformer编码\n",
    "        x = self.encoder(x, self.training)\n",
    "        \n",
    "        # 分类\n",
    "        x = x[:, 0]  # 取分类token\n",
    "        x = self.pre_logits(x)\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def train(net,file_name):\n",
    "    # the network optimizer\n",
    "    optimizer = getattr(optim, optim_name)(net.parameters(), **optim_kwargs)\n",
    "\n",
    "    # loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # training loop\n",
    "    # training loop\n",
    "    net.train()\n",
    "\n",
    "    outputs = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_t = 0\n",
    "        running_loss = 0.0\n",
    "        for i, (img, target) in enumerate(loader[\"train\"]):\n",
    "            s = time()\n",
    "            img, target = img.to(device), target.to(device)\n",
    "\n",
    "            pred = net(img)\n",
    "            loss = criterion(pred, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            e = time()\n",
    "            epoch_t += e - s\n",
    "            if i ==0:\n",
    "                output = f\"time: {e-s:.3f} seconds\"\n",
    "                print(output)\n",
    "            \n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % print_every == print_every - 1:\n",
    "                output = f\"[epoch={epoch + 1:3d}, iter={i + 1:5d}] loss: {running_loss / print_every:.3f} epoch time: {epoch_t:.3f} seconds\"\n",
    "                print(output)\n",
    "                outputs.append(output)\n",
    "                \n",
    "                with open(file_name, \"w\") as f:\n",
    "                    for out in outputs:\n",
    "                        f.write(out + \"\\n\")\n",
    "                running_loss = 0.0\n",
    "                epoch_t = 0\n",
    "    print(\"Finished Training\")\n",
    "    return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net):\n",
    "    net.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img, target in loader[\"test\"]:\n",
    "            img, target = img.to(device), target.to(device)\n",
    "            \n",
    "            # make prediction\n",
    "            pred = net(img)\n",
    "            \n",
    "            # accumulate\n",
    "            total += len(target)\n",
    "            correct += (torch.argmax(pred, dim=1) == target).sum().item()\n",
    "\n",
    "    output = f\"Accuracy of the network on the {total} test images: {100 * correct / total:.2f}%\"\n",
    "\n",
    "    print(output)\n",
    "    return  output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.69M\n",
      "time: 0.561 seconds\n",
      "[epoch=  1, iter=  200] loss: 2.009 epoch time: 3.488 seconds\n",
      "[epoch=  1, iter=  400] loss: 1.822 epoch time: 3.248 seconds\n",
      "[epoch=  1, iter=  600] loss: 1.739 epoch time: 3.616 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch=  2, iter=  200] loss: 1.642 epoch time: 3.472 seconds\n",
      "[epoch=  2, iter=  400] loss: 1.576 epoch time: 3.538 seconds\n",
      "[epoch=  2, iter=  600] loss: 1.521 epoch time: 3.918 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=  3, iter=  200] loss: 1.470 epoch time: 3.121 seconds\n",
      "[epoch=  3, iter=  400] loss: 1.448 epoch time: 3.382 seconds\n",
      "[epoch=  3, iter=  600] loss: 1.408 epoch time: 3.691 seconds\n",
      "time: 0.029 seconds\n",
      "[epoch=  4, iter=  200] loss: 1.374 epoch time: 3.230 seconds\n",
      "[epoch=  4, iter=  400] loss: 1.373 epoch time: 3.044 seconds\n",
      "[epoch=  4, iter=  600] loss: 1.360 epoch time: 3.083 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=  5, iter=  200] loss: 1.320 epoch time: 3.164 seconds\n",
      "[epoch=  5, iter=  400] loss: 1.318 epoch time: 3.287 seconds\n",
      "[epoch=  5, iter=  600] loss: 1.317 epoch time: 3.339 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=  6, iter=  200] loss: 1.288 epoch time: 3.572 seconds\n",
      "[epoch=  6, iter=  400] loss: 1.286 epoch time: 3.487 seconds\n",
      "[epoch=  6, iter=  600] loss: 1.267 epoch time: 2.794 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=  7, iter=  200] loss: 1.249 epoch time: 2.937 seconds\n",
      "[epoch=  7, iter=  400] loss: 1.238 epoch time: 2.962 seconds\n",
      "[epoch=  7, iter=  600] loss: 1.251 epoch time: 3.230 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch=  8, iter=  200] loss: 1.232 epoch time: 3.496 seconds\n",
      "[epoch=  8, iter=  400] loss: 1.225 epoch time: 3.337 seconds\n",
      "[epoch=  8, iter=  600] loss: 1.211 epoch time: 3.409 seconds\n",
      "time: 0.027 seconds\n",
      "[epoch=  9, iter=  200] loss: 1.175 epoch time: 3.697 seconds\n",
      "[epoch=  9, iter=  400] loss: 1.204 epoch time: 3.370 seconds\n",
      "[epoch=  9, iter=  600] loss: 1.196 epoch time: 3.131 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 10, iter=  200] loss: 1.185 epoch time: 3.056 seconds\n",
      "[epoch= 10, iter=  400] loss: 1.156 epoch time: 3.263 seconds\n",
      "[epoch= 10, iter=  600] loss: 1.177 epoch time: 3.289 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 11, iter=  200] loss: 1.137 epoch time: 3.064 seconds\n",
      "[epoch= 11, iter=  400] loss: 1.156 epoch time: 2.933 seconds\n",
      "[epoch= 11, iter=  600] loss: 1.134 epoch time: 3.119 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 12, iter=  200] loss: 1.122 epoch time: 2.883 seconds\n",
      "[epoch= 12, iter=  400] loss: 1.122 epoch time: 2.912 seconds\n",
      "[epoch= 12, iter=  600] loss: 1.138 epoch time: 2.984 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 13, iter=  200] loss: 1.102 epoch time: 2.943 seconds\n",
      "[epoch= 13, iter=  400] loss: 1.099 epoch time: 3.393 seconds\n",
      "[epoch= 13, iter=  600] loss: 1.097 epoch time: 3.687 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 14, iter=  200] loss: 1.074 epoch time: 3.649 seconds\n",
      "[epoch= 14, iter=  400] loss: 1.082 epoch time: 3.235 seconds\n",
      "[epoch= 14, iter=  600] loss: 1.079 epoch time: 3.114 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 15, iter=  200] loss: 1.059 epoch time: 3.230 seconds\n",
      "[epoch= 15, iter=  400] loss: 1.066 epoch time: 3.049 seconds\n",
      "[epoch= 15, iter=  600] loss: 1.069 epoch time: 2.914 seconds\n",
      "time: 0.027 seconds\n",
      "[epoch= 16, iter=  200] loss: 1.044 epoch time: 3.378 seconds\n",
      "[epoch= 16, iter=  400] loss: 1.043 epoch time: 3.774 seconds\n",
      "[epoch= 16, iter=  600] loss: 1.057 epoch time: 4.412 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 17, iter=  200] loss: 1.050 epoch time: 3.044 seconds\n",
      "[epoch= 17, iter=  400] loss: 1.048 epoch time: 3.031 seconds\n",
      "[epoch= 17, iter=  600] loss: 1.025 epoch time: 3.029 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 18, iter=  200] loss: 1.025 epoch time: 2.886 seconds\n",
      "[epoch= 18, iter=  400] loss: 1.015 epoch time: 2.858 seconds\n",
      "[epoch= 18, iter=  600] loss: 1.015 epoch time: 2.924 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 19, iter=  200] loss: 1.000 epoch time: 2.839 seconds\n",
      "[epoch= 19, iter=  400] loss: 1.002 epoch time: 2.714 seconds\n",
      "[epoch= 19, iter=  600] loss: 1.008 epoch time: 2.754 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 20, iter=  200] loss: 0.971 epoch time: 3.226 seconds\n",
      "[epoch= 20, iter=  400] loss: 0.972 epoch time: 2.983 seconds\n",
      "[epoch= 20, iter=  600] loss: 0.994 epoch time: 3.333 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 21, iter=  200] loss: 0.982 epoch time: 3.030 seconds\n",
      "[epoch= 21, iter=  400] loss: 0.967 epoch time: 2.919 seconds\n",
      "[epoch= 21, iter=  600] loss: 0.968 epoch time: 2.936 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 22, iter=  200] loss: 0.950 epoch time: 3.181 seconds\n",
      "[epoch= 22, iter=  400] loss: 0.941 epoch time: 3.233 seconds\n",
      "[epoch= 22, iter=  600] loss: 0.976 epoch time: 3.105 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 23, iter=  200] loss: 0.926 epoch time: 3.062 seconds\n",
      "[epoch= 23, iter=  400] loss: 0.950 epoch time: 3.151 seconds\n",
      "[epoch= 23, iter=  600] loss: 0.955 epoch time: 3.024 seconds\n",
      "time: 0.029 seconds\n",
      "[epoch= 24, iter=  200] loss: 0.922 epoch time: 3.013 seconds\n",
      "[epoch= 24, iter=  400] loss: 0.934 epoch time: 2.781 seconds\n",
      "[epoch= 24, iter=  600] loss: 0.940 epoch time: 2.783 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 25, iter=  200] loss: 0.920 epoch time: 2.743 seconds\n",
      "[epoch= 25, iter=  400] loss: 0.911 epoch time: 2.780 seconds\n",
      "[epoch= 25, iter=  600] loss: 0.916 epoch time: 2.837 seconds\n",
      "time: 0.026 seconds\n",
      "[epoch= 26, iter=  200] loss: 0.906 epoch time: 3.183 seconds\n",
      "[epoch= 26, iter=  400] loss: 0.901 epoch time: 3.201 seconds\n",
      "[epoch= 26, iter=  600] loss: 0.906 epoch time: 3.230 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 27, iter=  200] loss: 0.887 epoch time: 3.315 seconds\n",
      "[epoch= 27, iter=  400] loss: 0.884 epoch time: 3.974 seconds\n",
      "[epoch= 27, iter=  600] loss: 0.898 epoch time: 4.022 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 28, iter=  200] loss: 0.865 epoch time: 3.125 seconds\n",
      "[epoch= 28, iter=  400] loss: 0.880 epoch time: 3.180 seconds\n",
      "[epoch= 28, iter=  600] loss: 0.883 epoch time: 3.116 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 29, iter=  200] loss: 0.864 epoch time: 3.109 seconds\n",
      "[epoch= 29, iter=  400] loss: 0.851 epoch time: 3.046 seconds\n",
      "[epoch= 29, iter=  600] loss: 0.854 epoch time: 3.052 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 30, iter=  200] loss: 0.851 epoch time: 3.123 seconds\n",
      "[epoch= 30, iter=  400] loss: 0.854 epoch time: 3.292 seconds\n",
      "[epoch= 30, iter=  600] loss: 0.856 epoch time: 3.264 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 31, iter=  200] loss: 0.825 epoch time: 3.345 seconds\n",
      "[epoch= 31, iter=  400] loss: 0.846 epoch time: 3.075 seconds\n",
      "[epoch= 31, iter=  600] loss: 0.844 epoch time: 2.977 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 32, iter=  200] loss: 0.821 epoch time: 2.987 seconds\n",
      "[epoch= 32, iter=  400] loss: 0.832 epoch time: 3.179 seconds\n",
      "[epoch= 32, iter=  600] loss: 0.827 epoch time: 3.451 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 33, iter=  200] loss: 0.810 epoch time: 3.152 seconds\n",
      "[epoch= 33, iter=  400] loss: 0.829 epoch time: 3.101 seconds\n",
      "[epoch= 33, iter=  600] loss: 0.831 epoch time: 3.433 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 34, iter=  200] loss: 0.809 epoch time: 3.449 seconds\n",
      "[epoch= 34, iter=  400] loss: 0.801 epoch time: 3.322 seconds\n",
      "[epoch= 34, iter=  600] loss: 0.798 epoch time: 3.389 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 35, iter=  200] loss: 0.788 epoch time: 3.222 seconds\n",
      "[epoch= 35, iter=  400] loss: 0.801 epoch time: 3.181 seconds\n",
      "[epoch= 35, iter=  600] loss: 0.796 epoch time: 3.179 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 36, iter=  200] loss: 0.772 epoch time: 2.986 seconds\n",
      "[epoch= 36, iter=  400] loss: 0.792 epoch time: 3.332 seconds\n",
      "[epoch= 36, iter=  600] loss: 0.807 epoch time: 3.578 seconds\n",
      "time: 0.025 seconds\n",
      "[epoch= 37, iter=  200] loss: 0.764 epoch time: 3.603 seconds\n",
      "[epoch= 37, iter=  400] loss: 0.773 epoch time: 3.528 seconds\n",
      "[epoch= 37, iter=  600] loss: 0.776 epoch time: 3.118 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 38, iter=  200] loss: 0.756 epoch time: 2.796 seconds\n",
      "[epoch= 38, iter=  400] loss: 0.755 epoch time: 2.791 seconds\n",
      "[epoch= 38, iter=  600] loss: 0.763 epoch time: 2.744 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 39, iter=  200] loss: 0.737 epoch time: 2.935 seconds\n",
      "[epoch= 39, iter=  400] loss: 0.757 epoch time: 3.210 seconds\n",
      "[epoch= 39, iter=  600] loss: 0.756 epoch time: 3.371 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 40, iter=  200] loss: 0.729 epoch time: 2.892 seconds\n",
      "[epoch= 40, iter=  400] loss: 0.722 epoch time: 2.913 seconds\n",
      "[epoch= 40, iter=  600] loss: 0.736 epoch time: 2.867 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 41, iter=  200] loss: 0.718 epoch time: 2.916 seconds\n",
      "[epoch= 41, iter=  400] loss: 0.719 epoch time: 3.369 seconds\n",
      "[epoch= 41, iter=  600] loss: 0.710 epoch time: 3.106 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 42, iter=  200] loss: 0.711 epoch time: 3.567 seconds\n",
      "[epoch= 42, iter=  400] loss: 0.720 epoch time: 3.197 seconds\n",
      "[epoch= 42, iter=  600] loss: 0.715 epoch time: 3.073 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 43, iter=  200] loss: 0.693 epoch time: 2.822 seconds\n",
      "[epoch= 43, iter=  400] loss: 0.713 epoch time: 2.834 seconds\n",
      "[epoch= 43, iter=  600] loss: 0.711 epoch time: 2.847 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 44, iter=  200] loss: 0.694 epoch time: 2.837 seconds\n",
      "[epoch= 44, iter=  400] loss: 0.685 epoch time: 2.757 seconds\n",
      "[epoch= 44, iter=  600] loss: 0.704 epoch time: 2.878 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 45, iter=  200] loss: 0.664 epoch time: 3.099 seconds\n",
      "[epoch= 45, iter=  400] loss: 0.690 epoch time: 2.710 seconds\n",
      "[epoch= 45, iter=  600] loss: 0.689 epoch time: 2.883 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 46, iter=  200] loss: 0.661 epoch time: 3.079 seconds\n",
      "[epoch= 46, iter=  400] loss: 0.680 epoch time: 3.324 seconds\n",
      "[epoch= 46, iter=  600] loss: 0.685 epoch time: 3.046 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 47, iter=  200] loss: 0.659 epoch time: 2.750 seconds\n",
      "[epoch= 47, iter=  400] loss: 0.662 epoch time: 2.683 seconds\n",
      "[epoch= 47, iter=  600] loss: 0.661 epoch time: 2.776 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 48, iter=  200] loss: 0.621 epoch time: 3.045 seconds\n",
      "[epoch= 48, iter=  400] loss: 0.655 epoch time: 3.375 seconds\n",
      "[epoch= 48, iter=  600] loss: 0.663 epoch time: 3.326 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 49, iter=  200] loss: 0.628 epoch time: 3.042 seconds\n",
      "[epoch= 49, iter=  400] loss: 0.638 epoch time: 2.931 seconds\n",
      "[epoch= 49, iter=  600] loss: 0.657 epoch time: 2.888 seconds\n",
      "time: 0.026 seconds\n",
      "[epoch= 50, iter=  200] loss: 0.628 epoch time: 3.012 seconds\n",
      "[epoch= 50, iter=  400] loss: 0.620 epoch time: 3.074 seconds\n",
      "[epoch= 50, iter=  600] loss: 0.639 epoch time: 3.087 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 51, iter=  200] loss: 0.613 epoch time: 3.206 seconds\n",
      "[epoch= 51, iter=  400] loss: 0.633 epoch time: 3.283 seconds\n",
      "[epoch= 51, iter=  600] loss: 0.615 epoch time: 3.134 seconds\n",
      "time: 0.025 seconds\n",
      "[epoch= 52, iter=  200] loss: 0.591 epoch time: 3.750 seconds\n",
      "[epoch= 52, iter=  400] loss: 0.619 epoch time: 3.676 seconds\n",
      "[epoch= 52, iter=  600] loss: 0.622 epoch time: 3.660 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 53, iter=  200] loss: 0.585 epoch time: 3.417 seconds\n",
      "[epoch= 53, iter=  400] loss: 0.611 epoch time: 3.264 seconds\n",
      "[epoch= 53, iter=  600] loss: 0.620 epoch time: 2.877 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 54, iter=  200] loss: 0.579 epoch time: 3.184 seconds\n",
      "[epoch= 54, iter=  400] loss: 0.595 epoch time: 3.378 seconds\n",
      "[epoch= 54, iter=  600] loss: 0.621 epoch time: 3.074 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 55, iter=  200] loss: 0.580 epoch time: 3.141 seconds\n",
      "[epoch= 55, iter=  400] loss: 0.576 epoch time: 3.567 seconds\n",
      "[epoch= 55, iter=  600] loss: 0.606 epoch time: 4.031 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 56, iter=  200] loss: 0.557 epoch time: 3.063 seconds\n",
      "[epoch= 56, iter=  400] loss: 0.562 epoch time: 3.190 seconds\n",
      "[epoch= 56, iter=  600] loss: 0.591 epoch time: 3.357 seconds\n",
      "time: 0.026 seconds\n",
      "[epoch= 57, iter=  200] loss: 0.557 epoch time: 3.836 seconds\n",
      "[epoch= 57, iter=  400] loss: 0.560 epoch time: 3.221 seconds\n",
      "[epoch= 57, iter=  600] loss: 0.580 epoch time: 3.271 seconds\n",
      "time: 0.026 seconds\n",
      "[epoch= 58, iter=  200] loss: 0.540 epoch time: 2.790 seconds\n",
      "[epoch= 58, iter=  400] loss: 0.558 epoch time: 2.735 seconds\n",
      "[epoch= 58, iter=  600] loss: 0.578 epoch time: 2.940 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 59, iter=  200] loss: 0.560 epoch time: 2.956 seconds\n",
      "[epoch= 59, iter=  400] loss: 0.544 epoch time: 2.989 seconds\n",
      "[epoch= 59, iter=  600] loss: 0.548 epoch time: 3.024 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 60, iter=  200] loss: 0.518 epoch time: 3.073 seconds\n",
      "[epoch= 60, iter=  400] loss: 0.528 epoch time: 2.903 seconds\n",
      "[epoch= 60, iter=  600] loss: 0.548 epoch time: 2.883 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 61, iter=  200] loss: 0.518 epoch time: 3.333 seconds\n",
      "[epoch= 61, iter=  400] loss: 0.526 epoch time: 3.188 seconds\n",
      "[epoch= 61, iter=  600] loss: 0.542 epoch time: 3.432 seconds\n",
      "time: 0.027 seconds\n",
      "[epoch= 62, iter=  200] loss: 0.508 epoch time: 2.980 seconds\n",
      "[epoch= 62, iter=  400] loss: 0.525 epoch time: 2.926 seconds\n",
      "[epoch= 62, iter=  600] loss: 0.523 epoch time: 2.677 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 63, iter=  200] loss: 0.489 epoch time: 3.181 seconds\n",
      "[epoch= 63, iter=  400] loss: 0.522 epoch time: 3.138 seconds\n",
      "[epoch= 63, iter=  600] loss: 0.515 epoch time: 3.318 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 64, iter=  200] loss: 0.474 epoch time: 3.509 seconds\n",
      "[epoch= 64, iter=  400] loss: 0.519 epoch time: 3.735 seconds\n",
      "[epoch= 64, iter=  600] loss: 0.520 epoch time: 3.109 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 65, iter=  200] loss: 0.496 epoch time: 3.392 seconds\n",
      "[epoch= 65, iter=  400] loss: 0.495 epoch time: 3.648 seconds\n",
      "[epoch= 65, iter=  600] loss: 0.481 epoch time: 3.199 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 66, iter=  200] loss: 0.466 epoch time: 2.999 seconds\n",
      "[epoch= 66, iter=  400] loss: 0.483 epoch time: 2.871 seconds\n",
      "[epoch= 66, iter=  600] loss: 0.506 epoch time: 3.255 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 67, iter=  200] loss: 0.474 epoch time: 3.101 seconds\n",
      "[epoch= 67, iter=  400] loss: 0.485 epoch time: 3.488 seconds\n",
      "[epoch= 67, iter=  600] loss: 0.487 epoch time: 3.315 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 68, iter=  200] loss: 0.463 epoch time: 3.130 seconds\n",
      "[epoch= 68, iter=  400] loss: 0.475 epoch time: 3.207 seconds\n",
      "[epoch= 68, iter=  600] loss: 0.484 epoch time: 3.259 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 69, iter=  200] loss: 0.450 epoch time: 2.859 seconds\n",
      "[epoch= 69, iter=  400] loss: 0.466 epoch time: 2.818 seconds\n",
      "[epoch= 69, iter=  600] loss: 0.477 epoch time: 2.936 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 70, iter=  200] loss: 0.449 epoch time: 2.938 seconds\n",
      "[epoch= 70, iter=  400] loss: 0.465 epoch time: 2.966 seconds\n",
      "[epoch= 70, iter=  600] loss: 0.472 epoch time: 2.868 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 71, iter=  200] loss: 0.433 epoch time: 2.920 seconds\n",
      "[epoch= 71, iter=  400] loss: 0.437 epoch time: 2.957 seconds\n",
      "[epoch= 71, iter=  600] loss: 0.463 epoch time: 2.908 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 72, iter=  200] loss: 0.425 epoch time: 3.447 seconds\n",
      "[epoch= 72, iter=  400] loss: 0.434 epoch time: 3.996 seconds\n",
      "[epoch= 72, iter=  600] loss: 0.449 epoch time: 4.094 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 73, iter=  200] loss: 0.428 epoch time: 2.727 seconds\n",
      "[epoch= 73, iter=  400] loss: 0.436 epoch time: 3.707 seconds\n",
      "[epoch= 73, iter=  600] loss: 0.418 epoch time: 3.718 seconds\n",
      "time: 0.025 seconds\n",
      "[epoch= 74, iter=  200] loss: 0.410 epoch time: 2.861 seconds\n",
      "[epoch= 74, iter=  400] loss: 0.423 epoch time: 2.922 seconds\n",
      "[epoch= 74, iter=  600] loss: 0.443 epoch time: 2.832 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 75, iter=  200] loss: 0.385 epoch time: 3.230 seconds\n",
      "[epoch= 75, iter=  400] loss: 0.420 epoch time: 3.093 seconds\n",
      "[epoch= 75, iter=  600] loss: 0.435 epoch time: 3.149 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 76, iter=  200] loss: 0.410 epoch time: 3.207 seconds\n",
      "[epoch= 76, iter=  400] loss: 0.419 epoch time: 3.250 seconds\n",
      "[epoch= 76, iter=  600] loss: 0.428 epoch time: 3.213 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 77, iter=  200] loss: 0.393 epoch time: 3.125 seconds\n",
      "[epoch= 77, iter=  400] loss: 0.402 epoch time: 3.048 seconds\n",
      "[epoch= 77, iter=  600] loss: 0.408 epoch time: 3.040 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 78, iter=  200] loss: 0.380 epoch time: 2.941 seconds\n",
      "[epoch= 78, iter=  400] loss: 0.409 epoch time: 3.037 seconds\n",
      "[epoch= 78, iter=  600] loss: 0.409 epoch time: 3.039 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 79, iter=  200] loss: 0.376 epoch time: 2.876 seconds\n",
      "[epoch= 79, iter=  400] loss: 0.391 epoch time: 3.041 seconds\n",
      "[epoch= 79, iter=  600] loss: 0.412 epoch time: 2.786 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 80, iter=  200] loss: 0.373 epoch time: 3.027 seconds\n",
      "[epoch= 80, iter=  400] loss: 0.379 epoch time: 2.921 seconds\n",
      "[epoch= 80, iter=  600] loss: 0.415 epoch time: 2.844 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 81, iter=  200] loss: 0.375 epoch time: 3.218 seconds\n",
      "[epoch= 81, iter=  400] loss: 0.397 epoch time: 3.104 seconds\n",
      "[epoch= 81, iter=  600] loss: 0.395 epoch time: 3.015 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 82, iter=  200] loss: 0.370 epoch time: 3.348 seconds\n",
      "[epoch= 82, iter=  400] loss: 0.372 epoch time: 3.350 seconds\n",
      "[epoch= 82, iter=  600] loss: 0.401 epoch time: 3.143 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 83, iter=  200] loss: 0.366 epoch time: 2.797 seconds\n",
      "[epoch= 83, iter=  400] loss: 0.359 epoch time: 2.794 seconds\n",
      "[epoch= 83, iter=  600] loss: 0.365 epoch time: 2.936 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 84, iter=  200] loss: 0.356 epoch time: 2.748 seconds\n",
      "[epoch= 84, iter=  400] loss: 0.367 epoch time: 2.782 seconds\n",
      "[epoch= 84, iter=  600] loss: 0.369 epoch time: 2.730 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 85, iter=  200] loss: 0.365 epoch time: 2.979 seconds\n",
      "[epoch= 85, iter=  400] loss: 0.364 epoch time: 3.086 seconds\n",
      "[epoch= 85, iter=  600] loss: 0.356 epoch time: 3.282 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 86, iter=  200] loss: 0.351 epoch time: 3.108 seconds\n",
      "[epoch= 86, iter=  400] loss: 0.356 epoch time: 2.883 seconds\n",
      "[epoch= 86, iter=  600] loss: 0.369 epoch time: 2.848 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 87, iter=  200] loss: 0.350 epoch time: 2.858 seconds\n",
      "[epoch= 87, iter=  400] loss: 0.351 epoch time: 3.088 seconds\n",
      "[epoch= 87, iter=  600] loss: 0.358 epoch time: 3.067 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch= 88, iter=  200] loss: 0.319 epoch time: 3.284 seconds\n",
      "[epoch= 88, iter=  400] loss: 0.338 epoch time: 3.226 seconds\n",
      "[epoch= 88, iter=  600] loss: 0.349 epoch time: 3.062 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 89, iter=  200] loss: 0.321 epoch time: 3.258 seconds\n",
      "[epoch= 89, iter=  400] loss: 0.346 epoch time: 3.029 seconds\n",
      "[epoch= 89, iter=  600] loss: 0.363 epoch time: 3.050 seconds\n",
      "time: 0.020 seconds\n",
      "[epoch= 90, iter=  200] loss: 0.315 epoch time: 2.998 seconds\n",
      "[epoch= 90, iter=  400] loss: 0.336 epoch time: 3.052 seconds\n",
      "[epoch= 90, iter=  600] loss: 0.358 epoch time: 3.021 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 91, iter=  200] loss: 0.310 epoch time: 3.029 seconds\n",
      "[epoch= 91, iter=  400] loss: 0.331 epoch time: 3.018 seconds\n",
      "[epoch= 91, iter=  600] loss: 0.338 epoch time: 2.874 seconds\n",
      "time: 0.027 seconds\n",
      "[epoch= 92, iter=  200] loss: 0.320 epoch time: 3.576 seconds\n",
      "[epoch= 92, iter=  400] loss: 0.330 epoch time: 2.906 seconds\n",
      "[epoch= 92, iter=  600] loss: 0.341 epoch time: 3.008 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch= 93, iter=  200] loss: 0.319 epoch time: 3.498 seconds\n",
      "[epoch= 93, iter=  400] loss: 0.319 epoch time: 2.980 seconds\n",
      "[epoch= 93, iter=  600] loss: 0.336 epoch time: 3.245 seconds\n",
      "time: 0.031 seconds\n",
      "[epoch= 94, iter=  200] loss: 0.301 epoch time: 2.801 seconds\n",
      "[epoch= 94, iter=  400] loss: 0.300 epoch time: 2.970 seconds\n",
      "[epoch= 94, iter=  600] loss: 0.342 epoch time: 3.063 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 95, iter=  200] loss: 0.295 epoch time: 2.900 seconds\n",
      "[epoch= 95, iter=  400] loss: 0.308 epoch time: 2.961 seconds\n",
      "[epoch= 95, iter=  600] loss: 0.321 epoch time: 3.015 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 96, iter=  200] loss: 0.290 epoch time: 3.332 seconds\n",
      "[epoch= 96, iter=  400] loss: 0.305 epoch time: 3.151 seconds\n",
      "[epoch= 96, iter=  600] loss: 0.331 epoch time: 3.174 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 97, iter=  200] loss: 0.282 epoch time: 3.870 seconds\n",
      "[epoch= 97, iter=  400] loss: 0.316 epoch time: 3.389 seconds\n",
      "[epoch= 97, iter=  600] loss: 0.318 epoch time: 3.536 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch= 98, iter=  200] loss: 0.289 epoch time: 2.739 seconds\n",
      "[epoch= 98, iter=  400] loss: 0.294 epoch time: 2.688 seconds\n",
      "[epoch= 98, iter=  600] loss: 0.309 epoch time: 2.898 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch= 99, iter=  200] loss: 0.281 epoch time: 3.032 seconds\n",
      "[epoch= 99, iter=  400] loss: 0.300 epoch time: 3.132 seconds\n",
      "[epoch= 99, iter=  600] loss: 0.293 epoch time: 3.120 seconds\n",
      "time: 0.030 seconds\n",
      "[epoch=100, iter=  200] loss: 0.294 epoch time: 3.574 seconds\n",
      "[epoch=100, iter=  400] loss: 0.292 epoch time: 3.492 seconds\n",
      "[epoch=100, iter=  600] loss: 0.296 epoch time: 3.571 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=101, iter=  200] loss: 0.274 epoch time: 3.037 seconds\n",
      "[epoch=101, iter=  400] loss: 0.293 epoch time: 3.024 seconds\n",
      "[epoch=101, iter=  600] loss: 0.302 epoch time: 3.089 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch=102, iter=  200] loss: 0.268 epoch time: 2.980 seconds\n",
      "[epoch=102, iter=  400] loss: 0.280 epoch time: 2.903 seconds\n",
      "[epoch=102, iter=  600] loss: 0.294 epoch time: 2.901 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=103, iter=  200] loss: 0.268 epoch time: 3.050 seconds\n",
      "[epoch=103, iter=  400] loss: 0.269 epoch time: 3.010 seconds\n",
      "[epoch=103, iter=  600] loss: 0.299 epoch time: 3.044 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=104, iter=  200] loss: 0.256 epoch time: 2.961 seconds\n",
      "[epoch=104, iter=  400] loss: 0.284 epoch time: 3.002 seconds\n",
      "[epoch=104, iter=  600] loss: 0.287 epoch time: 3.012 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=105, iter=  200] loss: 0.262 epoch time: 2.973 seconds\n",
      "[epoch=105, iter=  400] loss: 0.260 epoch time: 2.990 seconds\n",
      "[epoch=105, iter=  600] loss: 0.273 epoch time: 2.959 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=106, iter=  200] loss: 0.255 epoch time: 3.017 seconds\n",
      "[epoch=106, iter=  400] loss: 0.257 epoch time: 3.005 seconds\n",
      "[epoch=106, iter=  600] loss: 0.284 epoch time: 3.115 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=107, iter=  200] loss: 0.259 epoch time: 2.928 seconds\n",
      "[epoch=107, iter=  400] loss: 0.264 epoch time: 3.215 seconds\n",
      "[epoch=107, iter=  600] loss: 0.266 epoch time: 3.176 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=108, iter=  200] loss: 0.249 epoch time: 3.274 seconds\n",
      "[epoch=108, iter=  400] loss: 0.253 epoch time: 3.126 seconds\n",
      "[epoch=108, iter=  600] loss: 0.263 epoch time: 3.086 seconds\n",
      "time: 0.025 seconds\n",
      "[epoch=109, iter=  200] loss: 0.251 epoch time: 3.381 seconds\n",
      "[epoch=109, iter=  400] loss: 0.269 epoch time: 3.035 seconds\n",
      "[epoch=109, iter=  600] loss: 0.259 epoch time: 3.184 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch=110, iter=  200] loss: 0.245 epoch time: 3.053 seconds\n",
      "[epoch=110, iter=  400] loss: 0.264 epoch time: 3.064 seconds\n",
      "[epoch=110, iter=  600] loss: 0.282 epoch time: 3.216 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=111, iter=  200] loss: 0.247 epoch time: 2.966 seconds\n",
      "[epoch=111, iter=  400] loss: 0.268 epoch time: 2.960 seconds\n",
      "[epoch=111, iter=  600] loss: 0.260 epoch time: 2.985 seconds\n",
      "time: 0.024 seconds\n",
      "[epoch=112, iter=  200] loss: 0.232 epoch time: 3.152 seconds\n",
      "[epoch=112, iter=  400] loss: 0.250 epoch time: 3.121 seconds\n",
      "[epoch=112, iter=  600] loss: 0.254 epoch time: 3.097 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=113, iter=  200] loss: 0.261 epoch time: 3.231 seconds\n",
      "[epoch=113, iter=  400] loss: 0.244 epoch time: 3.276 seconds\n",
      "[epoch=113, iter=  600] loss: 0.256 epoch time: 3.074 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=114, iter=  200] loss: 0.233 epoch time: 3.213 seconds\n",
      "[epoch=114, iter=  400] loss: 0.241 epoch time: 3.242 seconds\n",
      "[epoch=114, iter=  600] loss: 0.253 epoch time: 3.206 seconds\n",
      "time: 0.023 seconds\n",
      "[epoch=115, iter=  200] loss: 0.226 epoch time: 3.252 seconds\n",
      "[epoch=115, iter=  400] loss: 0.246 epoch time: 3.124 seconds\n",
      "[epoch=115, iter=  600] loss: 0.250 epoch time: 3.084 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=116, iter=  200] loss: 0.243 epoch time: 2.953 seconds\n",
      "[epoch=116, iter=  400] loss: 0.234 epoch time: 3.088 seconds\n",
      "[epoch=116, iter=  600] loss: 0.248 epoch time: 3.134 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=117, iter=  200] loss: 0.224 epoch time: 3.256 seconds\n",
      "[epoch=117, iter=  400] loss: 0.233 epoch time: 3.206 seconds\n",
      "[epoch=117, iter=  600] loss: 0.240 epoch time: 3.166 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=118, iter=  200] loss: 0.228 epoch time: 3.061 seconds\n",
      "[epoch=118, iter=  400] loss: 0.226 epoch time: 3.037 seconds\n",
      "[epoch=118, iter=  600] loss: 0.241 epoch time: 3.016 seconds\n",
      "time: 0.027 seconds\n",
      "[epoch=119, iter=  200] loss: 0.230 epoch time: 3.455 seconds\n",
      "[epoch=119, iter=  400] loss: 0.229 epoch time: 3.103 seconds\n",
      "[epoch=119, iter=  600] loss: 0.227 epoch time: 3.079 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=120, iter=  200] loss: 0.220 epoch time: 3.104 seconds\n",
      "[epoch=120, iter=  400] loss: 0.230 epoch time: 3.171 seconds\n",
      "[epoch=120, iter=  600] loss: 0.244 epoch time: 3.222 seconds\n",
      "time: 0.026 seconds\n",
      "[epoch=121, iter=  200] loss: 0.224 epoch time: 3.218 seconds\n",
      "[epoch=121, iter=  400] loss: 0.231 epoch time: 3.176 seconds\n",
      "[epoch=121, iter=  600] loss: 0.248 epoch time: 3.070 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=122, iter=  200] loss: 0.214 epoch time: 3.115 seconds\n",
      "[epoch=122, iter=  400] loss: 0.216 epoch time: 3.266 seconds\n",
      "[epoch=122, iter=  600] loss: 0.226 epoch time: 3.603 seconds\n",
      "time: 0.025 seconds\n",
      "[epoch=123, iter=  200] loss: 0.217 epoch time: 3.502 seconds\n",
      "[epoch=123, iter=  400] loss: 0.223 epoch time: 3.067 seconds\n",
      "[epoch=123, iter=  600] loss: 0.231 epoch time: 2.954 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=124, iter=  200] loss: 0.212 epoch time: 3.096 seconds\n",
      "[epoch=124, iter=  400] loss: 0.218 epoch time: 2.987 seconds\n",
      "[epoch=124, iter=  600] loss: 0.225 epoch time: 3.038 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=125, iter=  200] loss: 0.207 epoch time: 2.942 seconds\n",
      "[epoch=125, iter=  400] loss: 0.217 epoch time: 3.018 seconds\n",
      "[epoch=125, iter=  600] loss: 0.229 epoch time: 3.416 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=126, iter=  200] loss: 0.197 epoch time: 3.268 seconds\n",
      "[epoch=126, iter=  400] loss: 0.228 epoch time: 3.455 seconds\n",
      "[epoch=126, iter=  600] loss: 0.228 epoch time: 3.759 seconds\n",
      "time: 0.021 seconds\n",
      "[epoch=127, iter=  200] loss: 0.205 epoch time: 3.175 seconds\n",
      "[epoch=127, iter=  400] loss: 0.221 epoch time: 3.133 seconds\n",
      "[epoch=127, iter=  600] loss: 0.224 epoch time: 3.022 seconds\n",
      "time: 0.022 seconds\n",
      "[epoch=128, iter=  200] loss: 0.204 epoch time: 2.979 seconds\n",
      "[epoch=128, iter=  400] loss: 0.207 epoch time: 2.900 seconds\n",
      "[epoch=128, iter=  600] loss: 0.207 epoch time: 3.144 seconds\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 70.51%\n"
     ]
    }
   ],
   "source": [
    "net = VisionTransformer(\n",
    "                        num_classes=10,\n",
    "                            img_size=32,\n",
    "                            patch_size=4,\n",
    "                            hidden_dim=192,\n",
    "                            num_layers=6,\n",
    "                            num_heads=6,\n",
    "                            mlp_dim=768,\n",
    "                            dropout=0.1,\n",
    "                            attn_dropout=0.1,\n",
    "                            representation_size=None)\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")\n",
    "\n",
    "\n",
    "file_name = \"Vit_output.txt\"\n",
    "ops = train(net,file_name)\n",
    "ops.append(evaluate_accuracy(net))\n",
    "with open(file_name, \"w\") as f:\n",
    "    for out in ops:\n",
    "        f.write(out + \"\\n\")\n",
    " \n",
    "# TODO： 1. adamw 2 warmup 3 consine 4 big batch size \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 12.96M\n",
      "time: 0.091 seconds\n",
      "[epoch=  1, iter=  200] loss: 1.952 epoch time: 1.227 seconds\n",
      "[epoch=  1, iter=  400] loss: 1.670 epoch time: 1.116 seconds\n",
      "[epoch=  1, iter=  600] loss: 1.515 epoch time: 1.116 seconds\n",
      "time: 0.009 seconds\n"
     ]
    }
   ],
   "source": [
    "layer_dict = {\n",
    "    0: {'in_channels': 3, 'out_channels': 128, 'kernel_size': 3, 'Is_reg':False, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    1: {'in_channels': 128, 'out_channels': 256, 'kernel_size': 3, 'Is_reg': False, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    2: {'in_channels': 256, 'out_channels': 512, 'kernel_size': 3, 'Is_reg': False, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    3: {'in_channels': 512, 'out_channels': 1024, 'kernel_size': 3, 'Is_reg': False, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    4: {'in_channels': 1024, 'out_channels': 512, 'kernel_size': 3, 'Is_reg': True, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    5: {'in_channels': 512, 'out_channels': 256, 'kernel_size': 3, 'Is_reg': True, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "    6: {'in_channels': 256, 'out_channels': 128, 'kernel_size': 3, 'Is_reg': True, 'Is_BN': True, 'stride': 1, 'padding': 1, },\n",
    "}\n",
    "net  =nn.Sequential(\n",
    "ConvBs(7, layer_dict),\n",
    "nn.Flatten(),\n",
    "nn.Linear(128 * 4 * 4, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "nn.Linear(128, 10),\n",
    ")\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")\n",
    "\n",
    "\n",
    "\n",
    "file_name = \"BN_output.txt\"\n",
    "ops = train(net,file_name)\n",
    "ops.append(evaluate_accuracy(net))\n",
    "with open(file_name, \"w\") as f:\n",
    "    for out in ops:\n",
    "        f.write(out + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 7.28M\n",
      "time: 0.389 seconds\n",
      "[epoch=  1, iter=  200] loss: 2.198 epoch time: 1.002 seconds\n",
      "[epoch=  1, iter=  400] loss: 1.972 epoch time: 0.591 seconds\n",
      "[epoch=  1, iter=  600] loss: 1.856 epoch time: 0.673 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=  2, iter=  200] loss: 1.660 epoch time: 0.626 seconds\n",
      "[epoch=  2, iter=  400] loss: 1.603 epoch time: 0.613 seconds\n",
      "[epoch=  2, iter=  600] loss: 1.537 epoch time: 0.629 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=  3, iter=  200] loss: 1.467 epoch time: 0.642 seconds\n",
      "[epoch=  3, iter=  400] loss: 1.405 epoch time: 0.662 seconds\n",
      "[epoch=  3, iter=  600] loss: 1.385 epoch time: 0.675 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=  4, iter=  200] loss: 1.290 epoch time: 0.678 seconds\n",
      "[epoch=  4, iter=  400] loss: 1.267 epoch time: 0.665 seconds\n",
      "[epoch=  4, iter=  600] loss: 1.255 epoch time: 0.693 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=  5, iter=  200] loss: 1.185 epoch time: 0.687 seconds\n",
      "[epoch=  5, iter=  400] loss: 1.187 epoch time: 0.731 seconds\n",
      "[epoch=  5, iter=  600] loss: 1.153 epoch time: 0.685 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=  6, iter=  200] loss: 1.110 epoch time: 0.708 seconds\n",
      "[epoch=  6, iter=  400] loss: 1.097 epoch time: 0.672 seconds\n",
      "[epoch=  6, iter=  600] loss: 1.082 epoch time: 0.631 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=  7, iter=  200] loss: 1.042 epoch time: 0.584 seconds\n",
      "[epoch=  7, iter=  400] loss: 1.008 epoch time: 0.680 seconds\n",
      "[epoch=  7, iter=  600] loss: 1.006 epoch time: 0.674 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=  8, iter=  200] loss: 0.969 epoch time: 0.658 seconds\n",
      "[epoch=  8, iter=  400] loss: 0.988 epoch time: 0.789 seconds\n",
      "[epoch=  8, iter=  600] loss: 0.953 epoch time: 0.711 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=  9, iter=  200] loss: 0.938 epoch time: 0.687 seconds\n",
      "[epoch=  9, iter=  400] loss: 0.920 epoch time: 0.643 seconds\n",
      "[epoch=  9, iter=  600] loss: 0.921 epoch time: 0.687 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 10, iter=  200] loss: 0.873 epoch time: 0.660 seconds\n",
      "[epoch= 10, iter=  400] loss: 0.868 epoch time: 0.677 seconds\n",
      "[epoch= 10, iter=  600] loss: 0.859 epoch time: 0.657 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 11, iter=  200] loss: 0.832 epoch time: 0.654 seconds\n",
      "[epoch= 11, iter=  400] loss: 0.833 epoch time: 0.653 seconds\n",
      "[epoch= 11, iter=  600] loss: 0.838 epoch time: 0.660 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 12, iter=  200] loss: 0.801 epoch time: 0.701 seconds\n",
      "[epoch= 12, iter=  400] loss: 0.798 epoch time: 0.750 seconds\n",
      "[epoch= 12, iter=  600] loss: 0.791 epoch time: 0.730 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 13, iter=  200] loss: 0.773 epoch time: 0.713 seconds\n",
      "[epoch= 13, iter=  400] loss: 0.771 epoch time: 0.704 seconds\n",
      "[epoch= 13, iter=  600] loss: 0.769 epoch time: 0.650 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 14, iter=  200] loss: 0.732 epoch time: 0.637 seconds\n",
      "[epoch= 14, iter=  400] loss: 0.751 epoch time: 0.649 seconds\n",
      "[epoch= 14, iter=  600] loss: 0.732 epoch time: 0.634 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 15, iter=  200] loss: 0.712 epoch time: 0.688 seconds\n",
      "[epoch= 15, iter=  400] loss: 0.708 epoch time: 0.715 seconds\n",
      "[epoch= 15, iter=  600] loss: 0.702 epoch time: 0.653 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 16, iter=  200] loss: 0.699 epoch time: 0.662 seconds\n",
      "[epoch= 16, iter=  400] loss: 0.682 epoch time: 0.678 seconds\n",
      "[epoch= 16, iter=  600] loss: 0.687 epoch time: 0.683 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 17, iter=  200] loss: 0.672 epoch time: 0.881 seconds\n",
      "[epoch= 17, iter=  400] loss: 0.663 epoch time: 0.870 seconds\n",
      "[epoch= 17, iter=  600] loss: 0.687 epoch time: 0.870 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 18, iter=  200] loss: 0.640 epoch time: 0.680 seconds\n",
      "[epoch= 18, iter=  400] loss: 0.641 epoch time: 0.679 seconds\n",
      "[epoch= 18, iter=  600] loss: 0.648 epoch time: 0.674 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 19, iter=  200] loss: 0.619 epoch time: 0.669 seconds\n",
      "[epoch= 19, iter=  400] loss: 0.632 epoch time: 0.662 seconds\n",
      "[epoch= 19, iter=  600] loss: 0.633 epoch time: 0.659 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 20, iter=  200] loss: 0.607 epoch time: 0.647 seconds\n",
      "[epoch= 20, iter=  400] loss: 0.604 epoch time: 0.634 seconds\n",
      "[epoch= 20, iter=  600] loss: 0.621 epoch time: 0.635 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 21, iter=  200] loss: 0.588 epoch time: 0.625 seconds\n",
      "[epoch= 21, iter=  400] loss: 0.586 epoch time: 0.617 seconds\n",
      "[epoch= 21, iter=  600] loss: 0.599 epoch time: 0.664 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 22, iter=  200] loss: 0.580 epoch time: 0.639 seconds\n",
      "[epoch= 22, iter=  400] loss: 0.586 epoch time: 0.629 seconds\n",
      "[epoch= 22, iter=  600] loss: 0.585 epoch time: 0.634 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 23, iter=  200] loss: 0.572 epoch time: 0.655 seconds\n",
      "[epoch= 23, iter=  400] loss: 0.580 epoch time: 0.777 seconds\n",
      "[epoch= 23, iter=  600] loss: 0.579 epoch time: 0.758 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 24, iter=  200] loss: 0.551 epoch time: 0.642 seconds\n",
      "[epoch= 24, iter=  400] loss: 0.544 epoch time: 0.674 seconds\n",
      "[epoch= 24, iter=  600] loss: 0.562 epoch time: 0.683 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 25, iter=  200] loss: 0.538 epoch time: 0.731 seconds\n",
      "[epoch= 25, iter=  400] loss: 0.522 epoch time: 0.700 seconds\n",
      "[epoch= 25, iter=  600] loss: 0.553 epoch time: 0.681 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 26, iter=  200] loss: 0.516 epoch time: 0.724 seconds\n",
      "[epoch= 26, iter=  400] loss: 0.535 epoch time: 0.683 seconds\n",
      "[epoch= 26, iter=  600] loss: 0.529 epoch time: 0.589 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 27, iter=  200] loss: 0.518 epoch time: 0.585 seconds\n",
      "[epoch= 27, iter=  400] loss: 0.514 epoch time: 0.585 seconds\n",
      "[epoch= 27, iter=  600] loss: 0.540 epoch time: 0.598 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 28, iter=  200] loss: 0.501 epoch time: 0.601 seconds\n",
      "[epoch= 28, iter=  400] loss: 0.510 epoch time: 0.600 seconds\n",
      "[epoch= 28, iter=  600] loss: 0.506 epoch time: 0.746 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 29, iter=  200] loss: 0.492 epoch time: 0.661 seconds\n",
      "[epoch= 29, iter=  400] loss: 0.495 epoch time: 0.656 seconds\n",
      "[epoch= 29, iter=  600] loss: 0.495 epoch time: 0.646 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 30, iter=  200] loss: 0.478 epoch time: 0.725 seconds\n",
      "[epoch= 30, iter=  400] loss: 0.507 epoch time: 0.710 seconds\n",
      "[epoch= 30, iter=  600] loss: 0.498 epoch time: 0.726 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 31, iter=  200] loss: 0.489 epoch time: 0.724 seconds\n",
      "[epoch= 31, iter=  400] loss: 0.486 epoch time: 0.700 seconds\n",
      "[epoch= 31, iter=  600] loss: 0.498 epoch time: 0.656 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 32, iter=  200] loss: 0.472 epoch time: 0.670 seconds\n",
      "[epoch= 32, iter=  400] loss: 0.481 epoch time: 0.634 seconds\n",
      "[epoch= 32, iter=  600] loss: 0.479 epoch time: 0.642 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 33, iter=  200] loss: 0.479 epoch time: 0.664 seconds\n",
      "[epoch= 33, iter=  400] loss: 0.462 epoch time: 0.653 seconds\n",
      "[epoch= 33, iter=  600] loss: 0.469 epoch time: 0.641 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 34, iter=  200] loss: 0.453 epoch time: 0.621 seconds\n",
      "[epoch= 34, iter=  400] loss: 0.458 epoch time: 0.626 seconds\n",
      "[epoch= 34, iter=  600] loss: 0.449 epoch time: 0.632 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 35, iter=  200] loss: 0.441 epoch time: 0.643 seconds\n",
      "[epoch= 35, iter=  400] loss: 0.435 epoch time: 0.635 seconds\n",
      "[epoch= 35, iter=  600] loss: 0.472 epoch time: 0.627 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 36, iter=  200] loss: 0.464 epoch time: 0.687 seconds\n",
      "[epoch= 36, iter=  400] loss: 0.438 epoch time: 0.674 seconds\n",
      "[epoch= 36, iter=  600] loss: 0.451 epoch time: 0.687 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 37, iter=  200] loss: 0.433 epoch time: 0.687 seconds\n",
      "[epoch= 37, iter=  400] loss: 0.428 epoch time: 0.680 seconds\n",
      "[epoch= 37, iter=  600] loss: 0.437 epoch time: 0.731 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 38, iter=  200] loss: 0.422 epoch time: 0.964 seconds\n",
      "[epoch= 38, iter=  400] loss: 0.441 epoch time: 0.928 seconds\n",
      "[epoch= 38, iter=  600] loss: 0.421 epoch time: 0.719 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 39, iter=  200] loss: 0.418 epoch time: 0.626 seconds\n",
      "[epoch= 39, iter=  400] loss: 0.430 epoch time: 0.710 seconds\n",
      "[epoch= 39, iter=  600] loss: 0.431 epoch time: 0.665 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 40, iter=  200] loss: 0.424 epoch time: 0.641 seconds\n",
      "[epoch= 40, iter=  400] loss: 0.417 epoch time: 0.719 seconds\n",
      "[epoch= 40, iter=  600] loss: 0.419 epoch time: 0.705 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 41, iter=  200] loss: 0.403 epoch time: 0.698 seconds\n",
      "[epoch= 41, iter=  400] loss: 0.439 epoch time: 0.651 seconds\n",
      "[epoch= 41, iter=  600] loss: 0.410 epoch time: 0.673 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 42, iter=  200] loss: 0.393 epoch time: 0.650 seconds\n",
      "[epoch= 42, iter=  400] loss: 0.405 epoch time: 0.611 seconds\n",
      "[epoch= 42, iter=  600] loss: 0.412 epoch time: 0.607 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 43, iter=  200] loss: 0.393 epoch time: 0.650 seconds\n",
      "[epoch= 43, iter=  400] loss: 0.410 epoch time: 0.690 seconds\n",
      "[epoch= 43, iter=  600] loss: 0.389 epoch time: 0.617 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 44, iter=  200] loss: 0.394 epoch time: 0.612 seconds\n",
      "[epoch= 44, iter=  400] loss: 0.410 epoch time: 0.615 seconds\n",
      "[epoch= 44, iter=  600] loss: 0.404 epoch time: 0.600 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 45, iter=  200] loss: 0.374 epoch time: 0.681 seconds\n",
      "[epoch= 45, iter=  400] loss: 0.386 epoch time: 0.622 seconds\n",
      "[epoch= 45, iter=  600] loss: 0.397 epoch time: 0.618 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 46, iter=  200] loss: 0.366 epoch time: 0.790 seconds\n",
      "[epoch= 46, iter=  400] loss: 0.382 epoch time: 0.904 seconds\n",
      "[epoch= 46, iter=  600] loss: 0.386 epoch time: 0.939 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 47, iter=  200] loss: 0.362 epoch time: 0.636 seconds\n",
      "[epoch= 47, iter=  400] loss: 0.385 epoch time: 0.650 seconds\n",
      "[epoch= 47, iter=  600] loss: 0.386 epoch time: 0.649 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 48, iter=  200] loss: 0.375 epoch time: 0.715 seconds\n",
      "[epoch= 48, iter=  400] loss: 0.375 epoch time: 0.680 seconds\n",
      "[epoch= 48, iter=  600] loss: 0.380 epoch time: 0.631 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 49, iter=  200] loss: 0.382 epoch time: 0.658 seconds\n",
      "[epoch= 49, iter=  400] loss: 0.365 epoch time: 0.602 seconds\n",
      "[epoch= 49, iter=  600] loss: 0.385 epoch time: 0.597 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 50, iter=  200] loss: 0.361 epoch time: 0.616 seconds\n",
      "[epoch= 50, iter=  400] loss: 0.368 epoch time: 0.634 seconds\n",
      "[epoch= 50, iter=  600] loss: 0.382 epoch time: 0.628 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 51, iter=  200] loss: 0.362 epoch time: 0.595 seconds\n",
      "[epoch= 51, iter=  400] loss: 0.357 epoch time: 0.660 seconds\n",
      "[epoch= 51, iter=  600] loss: 0.376 epoch time: 0.690 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 52, iter=  200] loss: 0.359 epoch time: 0.693 seconds\n",
      "[epoch= 52, iter=  400] loss: 0.362 epoch time: 0.676 seconds\n",
      "[epoch= 52, iter=  600] loss: 0.363 epoch time: 0.678 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 53, iter=  200] loss: 0.334 epoch time: 0.696 seconds\n",
      "[epoch= 53, iter=  400] loss: 0.357 epoch time: 0.731 seconds\n",
      "[epoch= 53, iter=  600] loss: 0.358 epoch time: 0.691 seconds\n",
      "time: 0.010 seconds\n",
      "[epoch= 54, iter=  200] loss: 0.349 epoch time: 0.667 seconds\n",
      "[epoch= 54, iter=  400] loss: 0.353 epoch time: 0.740 seconds\n",
      "[epoch= 54, iter=  600] loss: 0.361 epoch time: 0.752 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 55, iter=  200] loss: 0.331 epoch time: 0.749 seconds\n",
      "[epoch= 55, iter=  400] loss: 0.343 epoch time: 0.673 seconds\n",
      "[epoch= 55, iter=  600] loss: 0.356 epoch time: 0.796 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 56, iter=  200] loss: 0.342 epoch time: 0.614 seconds\n",
      "[epoch= 56, iter=  400] loss: 0.349 epoch time: 0.643 seconds\n",
      "[epoch= 56, iter=  600] loss: 0.360 epoch time: 0.640 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 57, iter=  200] loss: 0.333 epoch time: 0.652 seconds\n",
      "[epoch= 57, iter=  400] loss: 0.342 epoch time: 0.708 seconds\n",
      "[epoch= 57, iter=  600] loss: 0.345 epoch time: 0.651 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 58, iter=  200] loss: 0.342 epoch time: 0.712 seconds\n",
      "[epoch= 58, iter=  400] loss: 0.340 epoch time: 0.760 seconds\n",
      "[epoch= 58, iter=  600] loss: 0.327 epoch time: 0.675 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 59, iter=  200] loss: 0.328 epoch time: 0.816 seconds\n",
      "[epoch= 59, iter=  400] loss: 0.337 epoch time: 0.765 seconds\n",
      "[epoch= 59, iter=  600] loss: 0.353 epoch time: 0.659 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 60, iter=  200] loss: 0.317 epoch time: 0.692 seconds\n",
      "[epoch= 60, iter=  400] loss: 0.333 epoch time: 0.647 seconds\n",
      "[epoch= 60, iter=  600] loss: 0.333 epoch time: 0.673 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 61, iter=  200] loss: 0.330 epoch time: 0.647 seconds\n",
      "[epoch= 61, iter=  400] loss: 0.321 epoch time: 0.617 seconds\n",
      "[epoch= 61, iter=  600] loss: 0.331 epoch time: 0.601 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 62, iter=  200] loss: 0.317 epoch time: 0.621 seconds\n",
      "[epoch= 62, iter=  400] loss: 0.320 epoch time: 0.619 seconds\n",
      "[epoch= 62, iter=  600] loss: 0.321 epoch time: 0.659 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 63, iter=  200] loss: 0.309 epoch time: 0.649 seconds\n",
      "[epoch= 63, iter=  400] loss: 0.308 epoch time: 0.624 seconds\n",
      "[epoch= 63, iter=  600] loss: 0.333 epoch time: 0.639 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 64, iter=  200] loss: 0.305 epoch time: 0.941 seconds\n",
      "[epoch= 64, iter=  400] loss: 0.317 epoch time: 0.726 seconds\n",
      "[epoch= 64, iter=  600] loss: 0.323 epoch time: 0.790 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 65, iter=  200] loss: 0.303 epoch time: 0.821 seconds\n",
      "[epoch= 65, iter=  400] loss: 0.328 epoch time: 0.723 seconds\n",
      "[epoch= 65, iter=  600] loss: 0.319 epoch time: 0.713 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 66, iter=  200] loss: 0.305 epoch time: 0.690 seconds\n",
      "[epoch= 66, iter=  400] loss: 0.307 epoch time: 0.687 seconds\n",
      "[epoch= 66, iter=  600] loss: 0.304 epoch time: 0.780 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 67, iter=  200] loss: 0.299 epoch time: 0.855 seconds\n",
      "[epoch= 67, iter=  400] loss: 0.310 epoch time: 0.825 seconds\n",
      "[epoch= 67, iter=  600] loss: 0.308 epoch time: 0.834 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 68, iter=  200] loss: 0.295 epoch time: 0.798 seconds\n",
      "[epoch= 68, iter=  400] loss: 0.305 epoch time: 0.775 seconds\n",
      "[epoch= 68, iter=  600] loss: 0.318 epoch time: 0.735 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 69, iter=  200] loss: 0.305 epoch time: 0.684 seconds\n",
      "[epoch= 69, iter=  400] loss: 0.298 epoch time: 0.721 seconds\n",
      "[epoch= 69, iter=  600] loss: 0.290 epoch time: 0.625 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 70, iter=  200] loss: 0.306 epoch time: 0.597 seconds\n",
      "[epoch= 70, iter=  400] loss: 0.304 epoch time: 0.589 seconds\n",
      "[epoch= 70, iter=  600] loss: 0.304 epoch time: 0.604 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 71, iter=  200] loss: 0.287 epoch time: 0.653 seconds\n",
      "[epoch= 71, iter=  400] loss: 0.312 epoch time: 0.659 seconds\n",
      "[epoch= 71, iter=  600] loss: 0.311 epoch time: 0.626 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 72, iter=  200] loss: 0.294 epoch time: 0.705 seconds\n",
      "[epoch= 72, iter=  400] loss: 0.288 epoch time: 0.710 seconds\n",
      "[epoch= 72, iter=  600] loss: 0.291 epoch time: 0.639 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 73, iter=  200] loss: 0.285 epoch time: 0.670 seconds\n",
      "[epoch= 73, iter=  400] loss: 0.290 epoch time: 0.664 seconds\n",
      "[epoch= 73, iter=  600] loss: 0.305 epoch time: 0.683 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 74, iter=  200] loss: 0.284 epoch time: 0.657 seconds\n",
      "[epoch= 74, iter=  400] loss: 0.294 epoch time: 0.663 seconds\n",
      "[epoch= 74, iter=  600] loss: 0.295 epoch time: 0.667 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 75, iter=  200] loss: 0.280 epoch time: 0.700 seconds\n",
      "[epoch= 75, iter=  400] loss: 0.279 epoch time: 0.834 seconds\n",
      "[epoch= 75, iter=  600] loss: 0.294 epoch time: 0.868 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 76, iter=  200] loss: 0.284 epoch time: 0.647 seconds\n",
      "[epoch= 76, iter=  400] loss: 0.292 epoch time: 0.630 seconds\n",
      "[epoch= 76, iter=  600] loss: 0.273 epoch time: 0.643 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 77, iter=  200] loss: 0.276 epoch time: 0.625 seconds\n",
      "[epoch= 77, iter=  400] loss: 0.271 epoch time: 0.577 seconds\n",
      "[epoch= 77, iter=  600] loss: 0.276 epoch time: 0.577 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 78, iter=  200] loss: 0.278 epoch time: 0.650 seconds\n",
      "[epoch= 78, iter=  400] loss: 0.285 epoch time: 0.692 seconds\n",
      "[epoch= 78, iter=  600] loss: 0.285 epoch time: 0.658 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 79, iter=  200] loss: 0.271 epoch time: 0.727 seconds\n",
      "[epoch= 79, iter=  400] loss: 0.276 epoch time: 0.689 seconds\n",
      "[epoch= 79, iter=  600] loss: 0.273 epoch time: 0.748 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 80, iter=  200] loss: 0.260 epoch time: 0.652 seconds\n",
      "[epoch= 80, iter=  400] loss: 0.267 epoch time: 0.700 seconds\n",
      "[epoch= 80, iter=  600] loss: 0.285 epoch time: 0.685 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 81, iter=  200] loss: 0.267 epoch time: 0.703 seconds\n",
      "[epoch= 81, iter=  400] loss: 0.270 epoch time: 0.717 seconds\n",
      "[epoch= 81, iter=  600] loss: 0.270 epoch time: 0.733 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 82, iter=  200] loss: 0.281 epoch time: 0.762 seconds\n",
      "[epoch= 82, iter=  400] loss: 0.278 epoch time: 0.675 seconds\n",
      "[epoch= 82, iter=  600] loss: 0.295 epoch time: 0.655 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch= 83, iter=  200] loss: 0.270 epoch time: 0.719 seconds\n",
      "[epoch= 83, iter=  400] loss: 0.266 epoch time: 0.709 seconds\n",
      "[epoch= 83, iter=  600] loss: 0.258 epoch time: 0.712 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 84, iter=  200] loss: 0.259 epoch time: 0.648 seconds\n",
      "[epoch= 84, iter=  400] loss: 0.275 epoch time: 0.616 seconds\n",
      "[epoch= 84, iter=  600] loss: 0.270 epoch time: 0.664 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 85, iter=  200] loss: 0.264 epoch time: 0.741 seconds\n",
      "[epoch= 85, iter=  400] loss: 0.245 epoch time: 0.914 seconds\n",
      "[epoch= 85, iter=  600] loss: 0.266 epoch time: 0.806 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 86, iter=  200] loss: 0.259 epoch time: 0.817 seconds\n",
      "[epoch= 86, iter=  400] loss: 0.263 epoch time: 0.777 seconds\n",
      "[epoch= 86, iter=  600] loss: 0.261 epoch time: 0.721 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 87, iter=  200] loss: 0.275 epoch time: 0.722 seconds\n",
      "[epoch= 87, iter=  400] loss: 0.267 epoch time: 0.789 seconds\n",
      "[epoch= 87, iter=  600] loss: 0.262 epoch time: 0.691 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 88, iter=  200] loss: 0.268 epoch time: 0.749 seconds\n",
      "[epoch= 88, iter=  400] loss: 0.266 epoch time: 0.731 seconds\n",
      "[epoch= 88, iter=  600] loss: 0.246 epoch time: 0.673 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 89, iter=  200] loss: 0.241 epoch time: 0.691 seconds\n",
      "[epoch= 89, iter=  400] loss: 0.254 epoch time: 0.733 seconds\n",
      "[epoch= 89, iter=  600] loss: 0.264 epoch time: 0.674 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 90, iter=  200] loss: 0.263 epoch time: 0.642 seconds\n",
      "[epoch= 90, iter=  400] loss: 0.266 epoch time: 0.756 seconds\n",
      "[epoch= 90, iter=  600] loss: 0.255 epoch time: 0.630 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 91, iter=  200] loss: 0.247 epoch time: 0.650 seconds\n",
      "[epoch= 91, iter=  400] loss: 0.265 epoch time: 0.631 seconds\n",
      "[epoch= 91, iter=  600] loss: 0.249 epoch time: 0.639 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 92, iter=  200] loss: 0.246 epoch time: 0.678 seconds\n",
      "[epoch= 92, iter=  400] loss: 0.253 epoch time: 0.698 seconds\n",
      "[epoch= 92, iter=  600] loss: 0.253 epoch time: 0.680 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 93, iter=  200] loss: 0.249 epoch time: 0.730 seconds\n",
      "[epoch= 93, iter=  400] loss: 0.241 epoch time: 0.713 seconds\n",
      "[epoch= 93, iter=  600] loss: 0.246 epoch time: 0.726 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch= 94, iter=  200] loss: 0.238 epoch time: 0.686 seconds\n",
      "[epoch= 94, iter=  400] loss: 0.242 epoch time: 0.695 seconds\n",
      "[epoch= 94, iter=  600] loss: 0.257 epoch time: 0.691 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 95, iter=  200] loss: 0.238 epoch time: 0.729 seconds\n",
      "[epoch= 95, iter=  400] loss: 0.251 epoch time: 0.667 seconds\n",
      "[epoch= 95, iter=  600] loss: 0.234 epoch time: 0.640 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 96, iter=  200] loss: 0.244 epoch time: 0.661 seconds\n",
      "[epoch= 96, iter=  400] loss: 0.246 epoch time: 0.653 seconds\n",
      "[epoch= 96, iter=  600] loss: 0.260 epoch time: 0.648 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 97, iter=  200] loss: 0.237 epoch time: 0.680 seconds\n",
      "[epoch= 97, iter=  400] loss: 0.234 epoch time: 0.615 seconds\n",
      "[epoch= 97, iter=  600] loss: 0.240 epoch time: 0.569 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 98, iter=  200] loss: 0.234 epoch time: 0.566 seconds\n",
      "[epoch= 98, iter=  400] loss: 0.240 epoch time: 0.575 seconds\n",
      "[epoch= 98, iter=  600] loss: 0.241 epoch time: 0.604 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch= 99, iter=  200] loss: 0.236 epoch time: 0.645 seconds\n",
      "[epoch= 99, iter=  400] loss: 0.247 epoch time: 0.677 seconds\n",
      "[epoch= 99, iter=  600] loss: 0.239 epoch time: 0.673 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=100, iter=  200] loss: 0.223 epoch time: 0.654 seconds\n",
      "[epoch=100, iter=  400] loss: 0.237 epoch time: 0.614 seconds\n",
      "[epoch=100, iter=  600] loss: 0.251 epoch time: 0.617 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=101, iter=  200] loss: 0.232 epoch time: 0.609 seconds\n",
      "[epoch=101, iter=  400] loss: 0.237 epoch time: 0.605 seconds\n",
      "[epoch=101, iter=  600] loss: 0.230 epoch time: 0.610 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=102, iter=  200] loss: 0.239 epoch time: 0.632 seconds\n",
      "[epoch=102, iter=  400] loss: 0.243 epoch time: 0.660 seconds\n",
      "[epoch=102, iter=  600] loss: 0.237 epoch time: 0.667 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=103, iter=  200] loss: 0.220 epoch time: 0.670 seconds\n",
      "[epoch=103, iter=  400] loss: 0.217 epoch time: 0.659 seconds\n",
      "[epoch=103, iter=  600] loss: 0.239 epoch time: 0.664 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=104, iter=  200] loss: 0.222 epoch time: 0.705 seconds\n",
      "[epoch=104, iter=  400] loss: 0.239 epoch time: 0.640 seconds\n",
      "[epoch=104, iter=  600] loss: 0.254 epoch time: 0.671 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=105, iter=  200] loss: 0.219 epoch time: 0.637 seconds\n",
      "[epoch=105, iter=  400] loss: 0.235 epoch time: 0.622 seconds\n",
      "[epoch=105, iter=  600] loss: 0.236 epoch time: 0.663 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=106, iter=  200] loss: 0.224 epoch time: 0.650 seconds\n",
      "[epoch=106, iter=  400] loss: 0.219 epoch time: 0.785 seconds\n",
      "[epoch=106, iter=  600] loss: 0.230 epoch time: 0.678 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=107, iter=  200] loss: 0.223 epoch time: 0.701 seconds\n",
      "[epoch=107, iter=  400] loss: 0.229 epoch time: 0.696 seconds\n",
      "[epoch=107, iter=  600] loss: 0.218 epoch time: 0.690 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=108, iter=  200] loss: 0.216 epoch time: 0.703 seconds\n",
      "[epoch=108, iter=  400] loss: 0.229 epoch time: 0.634 seconds\n",
      "[epoch=108, iter=  600] loss: 0.212 epoch time: 0.592 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=109, iter=  200] loss: 0.233 epoch time: 0.645 seconds\n",
      "[epoch=109, iter=  400] loss: 0.226 epoch time: 0.663 seconds\n",
      "[epoch=109, iter=  600] loss: 0.224 epoch time: 0.674 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=110, iter=  200] loss: 0.222 epoch time: 0.742 seconds\n",
      "[epoch=110, iter=  400] loss: 0.240 epoch time: 0.683 seconds\n",
      "[epoch=110, iter=  600] loss: 0.223 epoch time: 0.725 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=111, iter=  200] loss: 0.210 epoch time: 0.763 seconds\n",
      "[epoch=111, iter=  400] loss: 0.228 epoch time: 0.666 seconds\n",
      "[epoch=111, iter=  600] loss: 0.223 epoch time: 0.630 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=112, iter=  200] loss: 0.226 epoch time: 0.584 seconds\n",
      "[epoch=112, iter=  400] loss: 0.212 epoch time: 0.579 seconds\n",
      "[epoch=112, iter=  600] loss: 0.213 epoch time: 0.650 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=113, iter=  200] loss: 0.226 epoch time: 0.639 seconds\n",
      "[epoch=113, iter=  400] loss: 0.222 epoch time: 0.667 seconds\n",
      "[epoch=113, iter=  600] loss: 0.220 epoch time: 0.636 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=114, iter=  200] loss: 0.235 epoch time: 0.640 seconds\n",
      "[epoch=114, iter=  400] loss: 0.232 epoch time: 0.719 seconds\n",
      "[epoch=114, iter=  600] loss: 0.221 epoch time: 0.738 seconds\n",
      "time: 0.009 seconds\n",
      "[epoch=115, iter=  200] loss: 0.213 epoch time: 0.760 seconds\n",
      "[epoch=115, iter=  400] loss: 0.224 epoch time: 0.682 seconds\n",
      "[epoch=115, iter=  600] loss: 0.224 epoch time: 0.684 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=116, iter=  200] loss: 0.213 epoch time: 0.670 seconds\n",
      "[epoch=116, iter=  400] loss: 0.216 epoch time: 0.648 seconds\n",
      "[epoch=116, iter=  600] loss: 0.210 epoch time: 0.694 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=117, iter=  200] loss: 0.225 epoch time: 0.619 seconds\n",
      "[epoch=117, iter=  400] loss: 0.222 epoch time: 0.680 seconds\n",
      "[epoch=117, iter=  600] loss: 0.220 epoch time: 0.659 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=118, iter=  200] loss: 0.214 epoch time: 0.626 seconds\n",
      "[epoch=118, iter=  400] loss: 0.213 epoch time: 0.580 seconds\n",
      "[epoch=118, iter=  600] loss: 0.203 epoch time: 0.574 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=119, iter=  200] loss: 0.231 epoch time: 0.628 seconds\n",
      "[epoch=119, iter=  400] loss: 0.236 epoch time: 0.630 seconds\n",
      "[epoch=119, iter=  600] loss: 0.206 epoch time: 0.648 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=120, iter=  200] loss: 0.214 epoch time: 0.761 seconds\n",
      "[epoch=120, iter=  400] loss: 0.212 epoch time: 0.818 seconds\n",
      "[epoch=120, iter=  600] loss: 0.202 epoch time: 0.749 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=121, iter=  200] loss: 0.219 epoch time: 0.697 seconds\n",
      "[epoch=121, iter=  400] loss: 0.201 epoch time: 0.799 seconds\n",
      "[epoch=121, iter=  600] loss: 0.230 epoch time: 0.633 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=122, iter=  200] loss: 0.207 epoch time: 0.588 seconds\n",
      "[epoch=122, iter=  400] loss: 0.211 epoch time: 0.613 seconds\n",
      "[epoch=122, iter=  600] loss: 0.207 epoch time: 0.608 seconds\n",
      "time: 0.008 seconds\n",
      "[epoch=123, iter=  200] loss: 0.209 epoch time: 0.640 seconds\n",
      "[epoch=123, iter=  400] loss: 0.208 epoch time: 0.844 seconds\n",
      "[epoch=123, iter=  600] loss: 0.202 epoch time: 0.799 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=124, iter=  200] loss: 0.196 epoch time: 0.664 seconds\n",
      "[epoch=124, iter=  400] loss: 0.193 epoch time: 0.683 seconds\n",
      "[epoch=124, iter=  600] loss: 0.213 epoch time: 0.676 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=125, iter=  200] loss: 0.199 epoch time: 0.681 seconds\n",
      "[epoch=125, iter=  400] loss: 0.207 epoch time: 0.650 seconds\n",
      "[epoch=125, iter=  600] loss: 0.201 epoch time: 0.650 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=126, iter=  200] loss: 0.198 epoch time: 0.613 seconds\n",
      "[epoch=126, iter=  400] loss: 0.220 epoch time: 0.605 seconds\n",
      "[epoch=126, iter=  600] loss: 0.212 epoch time: 0.641 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=127, iter=  200] loss: 0.212 epoch time: 0.626 seconds\n",
      "[epoch=127, iter=  400] loss: 0.209 epoch time: 0.708 seconds\n",
      "[epoch=127, iter=  600] loss: 0.208 epoch time: 0.692 seconds\n",
      "time: 0.007 seconds\n",
      "[epoch=128, iter=  200] loss: 0.199 epoch time: 0.697 seconds\n",
      "[epoch=128, iter=  400] loss: 0.193 epoch time: 0.671 seconds\n",
      "[epoch=128, iter=  600] loss: 0.192 epoch time: 0.661 seconds\n",
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 86.60%\n"
     ]
    }
   ],
   "source": [
    "# our network architecture\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(3, 128, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(128, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Conv2d(256, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 512, 3, padding=1), nn.ReLU(inplace=True),\n",
    "    nn.Conv2d(512, 256, 3, padding=1), nn.ReLU(inplace=True), nn.MaxPool2d(2), nn.Dropout(0.3),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(256 * 4 * 4, 512), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(512, 256), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(256, 128), nn.ReLU(inplace=True), nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10),\n",
    ")\n",
    "\n",
    "# move to device\n",
    "net.to(device)\n",
    "\n",
    "# print the number of parameters\n",
    "print(f\"number of parameters: {sum(p.numel() for p in net.parameters() if p.requires_grad) / 1_000_000:.2f}M\")\n",
    "\n",
    "\n",
    "file_name = \"init_output.txt\"\n",
    "ops = train(net,file_name)\n",
    "ops.append(evaluate_accuracy(net))\n",
    "with open(file_name, \"w\") as f:\n",
    "    for out in ops:\n",
    "        f.write(out + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
