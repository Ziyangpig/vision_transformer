{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cc14a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q h5py typing-extensions wheel\n",
    "!pip install -q -U bitsandbytes\n",
    "!pip install -q -U fsspec==2025.3.0\n",
    "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "\n",
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca23b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True, # Activate nested quantization for 4-bit base models (double quantization)\n",
    "    bnb_4bit_quant_type=\"nf4\", # Quantization type (fp4 or nf4), According to QLoRA paper, for training 4-bit base models (e.g. using LoRA adapters) one should use\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d55fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "\n",
    "model.gradient_checkpointing_enable()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb15b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "\n",
    "from transformers import AutoModelForSeq2SeqLM \n",
    "from peft import LoraConfig, AdaLoraModel, AdaLoraConfig\n",
    "\n",
    "TARGET_MODULES=[\"q_proj\",\"k_proj\", \"v_proj\", \"gate_proj\", \"down_proj\",\"up_proj\"] #['q','k'] \n",
    "LORA_R = 8\n",
    "LORA_ALPHA = 8\n",
    "LORA_DROPOUT = 0.05\n",
    "init_lora_weights = 'pissa'\n",
    "rs = True\n",
    "dw = True\n",
    "config = AdaLoraConfig(\n",
    "    peft_type=\"ADALORA\", task_type=\"CAUSAL_LM\", bias=\"none\",\n",
    "    init_r=LORA_R,\n",
    "    lora_alpha=LORA_ALPHA,\n",
    "    lora_dropout=LORA_DROPOUT,\n",
    "    target_modules=TARGET_MODULES,\n",
    "    tinit=100,                            # 初始稳定步数（不调整秩）\n",
    "    tfinal=1000,                          # 开始动态调整的步数\n",
    "    deltaT=10,                            # 秩调整间隔步数\n",
    "    # \n",
    "    use_rslora = rs,\n",
    "    init_lora_weights = init_lora_weights,\n",
    "    use_dora=dw,\n",
    "  \n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "model = AdaLoraModel(model, config, \"default\")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e6bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = f\".{model_id}_rs{rs}_dw{dw}_{init_lora_weights}/checkpoints\"\n",
    "\n",
    "training_arguments = transformers.TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    optim='paged_adamw_32bit',    # \n",
    "    save_steps=0,\n",
    "    logging_steps=1,\n",
    "    learning_rate=2e-7,   # \n",
    "    weight_decay=0.001,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\", \n",
    "    gradient_checkpointing=True,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "    # evaluation_strategy = 'epoch',\n",
    "    # warmup_steps=50,\n",
    "    # fp16=True,\n",
    "    # logging_steps=50,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5b7577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainerCallback\n",
    "\n",
    "class AdaLoraUpdateCallback(TrainerCallback):\n",
    "    def on_step_end(self, args, state, control, **kwargs):\n",
    "        # 获取 AdaLora 配置\n",
    "        adalora_config = self.model.peft_config[self.model.trainable_adapter_name]\n",
    "        # 每隔 deltaT 步触发一次秩调整\n",
    "        if state.global_step % adalora_config.deltaT == 0:\n",
    "            self.model.update_and_allocate(state.global_step)\n",
    "            print(f\"Step {state.global_step}: Rank pattern updated to\")\n",
    "        return control\n",
    "\n",
    "# 初始化 Trainer 并添加回调\n",
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[AdaLoraUpdateCallback()],  # 关键！\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3815f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环中需周期性调用秩调整\n",
    "model.train()\n",
    "\n",
    "for step, batch in enumerate(train_loader):\n",
    "    outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 每隔 deltaT 步更新秩\n",
    "    if step > peft_config.tinit and step % peft_config.deltaT == 0:\n",
    "        model.update_and_allocate(step)  # 动态调整秩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278779de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {math.exp(eval_results['eval_loss']):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
